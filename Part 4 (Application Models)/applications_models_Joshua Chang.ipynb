{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses a wide variety of modeling algorithms for a binary classification problem. It reads a file created from a feature selection process that has a reasonably small number of good variables, and we know their order of multivariate importance because we used a proper wrapper method. We can explore # input variables, model algorithms and tune model hyperparameters. At the end we can select our favorite algorithm, run it again and build the final model performace score percentile tables.\n",
    "\n",
    "Here we call the larger fraction population the goods and the smaller fraction the bads. This notebook was originally\n",
    "written for fraud detection but can be used for any binary classification. It uses detection rate as an appropriate measure of goodness.\n",
    "\n",
    "Rather than use a built-in CV, we do a \"manual CV\" by running each model multiple (nitermax) times and average the performance on the training (trn), testing (tst) and out of time (oot) data sets.\n",
    "\n",
    "Some of the ML algorithms are very fast and some are slow. Feel free to comment out any cells/models you want. At the bottom of the notebook you can select your final model/hyperparameters to run one time only and then make the business perfoemance tables for that final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to add: better calculation of FDR@3% when building a model using sampled training data. Right now I just approximate it by using the entire population trntst for a model built with sampled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackboard Instructions:\n",
    "- Explore many different model algorithms and hyperparameter choices, building many preliminary models. Start with a linear regression as a baseline. For the nonlinear models start simple and increase complexity. Try to force and observe overfitting. Submit a single page document table that contains the results of these tests and explores. For each model test run the algorithm 5 times and record the average performace (FDR@3%) for the three data sets training, testing and out of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 22)\n",
      "CPU times: user 1.07 s, sys: 221 ms, total: 1.29 s\n",
      "Wall time: 1.43 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "      <th>...</th>\n",
       "      <th>address_unique_count_for_ssn_zip5_60</th>\n",
       "      <th>address_unique_count_for_ssn_name_60</th>\n",
       "      <th>address_unique_count_for_ssn_firstname_60</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_60</th>\n",
       "      <th>address_unique_count_for_dob_homephone_60</th>\n",
       "      <th>address_unique_count_for_ssn_homephone_60</th>\n",
       "      <th>address_unique_count_for_ssn_lastname_60</th>\n",
       "      <th>address_unique_count_for_ssn_60</th>\n",
       "      <th>record</th>\n",
       "      <th>fraud_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fulladdress_day_since  name_dob_count_30  \\\n",
       "0                  365.0                1.0   \n",
       "1                  365.0                1.0   \n",
       "2                  365.0                1.0   \n",
       "3                  365.0                1.0   \n",
       "4                  365.0                1.0   \n",
       "\n",
       "   address_unique_count_for_name_homephone_60  \\\n",
       "0                                         1.0   \n",
       "1                                         1.0   \n",
       "2                                         1.0   \n",
       "3                                         1.0   \n",
       "4                                         1.0   \n",
       "\n",
       "   fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "0                                           1.0   \n",
       "1                                           1.0   \n",
       "2                                           1.0   \n",
       "3                                           1.0   \n",
       "4                                           1.0   \n",
       "\n",
       "   address_unique_count_for_homephone_name_dob_30  \\\n",
       "0                                             1.0   \n",
       "1                                             1.0   \n",
       "2                                             1.0   \n",
       "3                                             1.0   \n",
       "4                                             1.0   \n",
       "\n",
       "   address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "0                                       1.0              365.0   \n",
       "1                                       1.0              365.0   \n",
       "2                                       1.0              365.0   \n",
       "3                                       1.0              365.0   \n",
       "4                                       1.0              365.0   \n",
       "\n",
       "   address_count_14  address_count_7  address_count_0_by_30  ...  \\\n",
       "0               1.0              1.0                   30.0  ...   \n",
       "1               1.0              1.0                   30.0  ...   \n",
       "2               1.0              1.0                   30.0  ...   \n",
       "3               1.0              1.0                   30.0  ...   \n",
       "4               1.0              1.0                   30.0  ...   \n",
       "\n",
       "   address_unique_count_for_ssn_zip5_60  address_unique_count_for_ssn_name_60  \\\n",
       "0                                   1.0                                   1.0   \n",
       "1                                   1.0                                   1.0   \n",
       "2                                   1.0                                   1.0   \n",
       "3                                   1.0                                   1.0   \n",
       "4                                   1.0                                   1.0   \n",
       "\n",
       "   address_unique_count_for_ssn_firstname_60  \\\n",
       "0                                        1.0   \n",
       "1                                        1.0   \n",
       "2                                        1.0   \n",
       "3                                        1.0   \n",
       "4                                        1.0   \n",
       "\n",
       "   address_unique_count_for_ssn_name_dob_60  \\\n",
       "0                                       1.0   \n",
       "1                                       1.0   \n",
       "2                                       1.0   \n",
       "3                                       1.0   \n",
       "4                                       1.0   \n",
       "\n",
       "   address_unique_count_for_dob_homephone_60  \\\n",
       "0                                        1.0   \n",
       "1                                        1.0   \n",
       "2                                        1.0   \n",
       "3                                        1.0   \n",
       "4                                        1.0   \n",
       "\n",
       "   address_unique_count_for_ssn_homephone_60  \\\n",
       "0                                        1.0   \n",
       "1                                        1.0   \n",
       "2                                        1.0   \n",
       "3                                        1.0   \n",
       "4                                        1.0   \n",
       "\n",
       "   address_unique_count_for_ssn_lastname_60  address_unique_count_for_ssn_60  \\\n",
       "0                                       1.0                              1.0   \n",
       "1                                       1.0                              1.0   \n",
       "2                                       1.0                              1.0   \n",
       "3                                       1.0                              1.0   \n",
       "4                                       1.0                              1.0   \n",
       "\n",
       "   record  fraud_label  \n",
       "0     1.0          0.0  \n",
       "1     2.0          1.0  \n",
       "2     3.0          0.0  \n",
       "3     4.0          0.0  \n",
       "4     5.0          0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vars = pd.read_csv('vars_final.csv')\n",
    "print(vars.shape)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recnum',\n",
       " 'Fraud',\n",
       " 'fulladdress_day_since',\n",
       " 'name_dob_count_30',\n",
       " 'address_unique_count_for_name_homephone_60',\n",
       " 'fulladdress_unique_count_for_dob_homephone_3',\n",
       " 'address_unique_count_for_homephone_name_dob_30',\n",
       " 'address_unique_count_for_ssn_name_dob_14',\n",
       " 'address_day_since',\n",
       " 'address_count_14',\n",
       " 'address_count_7',\n",
       " 'address_count_0_by_30']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the number of variables desired here, and set the names of the y and record number properly\n",
    "NVARS = 10\n",
    "\n",
    "vars.rename(columns={'record':'Recnum'},inplace=True)\n",
    "vars.rename(columns={'fraud_label':'Fraud'},inplace=True)\n",
    "numvars = min(NVARS,len(vars)-2)\n",
    "final_vars_list = ['Recnum','Fraud']\n",
    "for i in range(numvars):\n",
    "    final_vars_list.append(vars.columns[i])\n",
    "    \n",
    "final_vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  fulladdress_day_since  name_dob_count_30  \\\n",
       "0     1.0    0.0                  365.0                1.0   \n",
       "1     2.0    1.0                  365.0                1.0   \n",
       "2     3.0    0.0                  365.0                1.0   \n",
       "3     4.0    0.0                  365.0                1.0   \n",
       "4     5.0    0.0                  365.0                1.0   \n",
       "\n",
       "   address_unique_count_for_name_homephone_60  \\\n",
       "0                                         1.0   \n",
       "1                                         1.0   \n",
       "2                                         1.0   \n",
       "3                                         1.0   \n",
       "4                                         1.0   \n",
       "\n",
       "   fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "0                                           1.0   \n",
       "1                                           1.0   \n",
       "2                                           1.0   \n",
       "3                                           1.0   \n",
       "4                                           1.0   \n",
       "\n",
       "   address_unique_count_for_homephone_name_dob_30  \\\n",
       "0                                             1.0   \n",
       "1                                             1.0   \n",
       "2                                             1.0   \n",
       "3                                             1.0   \n",
       "4                                             1.0   \n",
       "\n",
       "   address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "0                                       1.0              365.0   \n",
       "1                                       1.0              365.0   \n",
       "2                                       1.0              365.0   \n",
       "3                                       1.0              365.0   \n",
       "4                                       1.0              365.0   \n",
       "\n",
       "   address_count_14  address_count_7  address_count_0_by_30  \n",
       "0               1.0              1.0                   30.0  \n",
       "1               1.0              1.0                   30.0  \n",
       "2               1.0              1.0                   30.0  \n",
       "3               1.0              1.0                   30.0  \n",
       "4               1.0              1.0                   30.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = vars.filter(final_vars_list,axis=1)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14393.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['Fraud'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  fulladdress_day_since  name_dob_count_30  \\\n",
       "0     1.0    0.0                  365.0                1.0   \n",
       "1     2.0    1.0                  365.0                1.0   \n",
       "2     3.0    0.0                  365.0                1.0   \n",
       "3     4.0    0.0                  365.0                1.0   \n",
       "4     5.0    0.0                  365.0                1.0   \n",
       "5     6.0    0.0                  365.0                1.0   \n",
       "6     7.0    0.0                  365.0                1.0   \n",
       "7     8.0    0.0                  365.0                1.0   \n",
       "8     9.0    0.0                  365.0                1.0   \n",
       "9    10.0    0.0                  365.0                1.0   \n",
       "\n",
       "   address_unique_count_for_name_homephone_60  \\\n",
       "0                                         1.0   \n",
       "1                                         1.0   \n",
       "2                                         1.0   \n",
       "3                                         1.0   \n",
       "4                                         1.0   \n",
       "5                                         1.0   \n",
       "6                                         1.0   \n",
       "7                                         1.0   \n",
       "8                                         1.0   \n",
       "9                                         1.0   \n",
       "\n",
       "   fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "0                                           1.0   \n",
       "1                                           1.0   \n",
       "2                                           1.0   \n",
       "3                                           1.0   \n",
       "4                                           1.0   \n",
       "5                                           1.0   \n",
       "6                                           1.0   \n",
       "7                                           1.0   \n",
       "8                                           1.0   \n",
       "9                                           1.0   \n",
       "\n",
       "   address_unique_count_for_homephone_name_dob_30  \\\n",
       "0                                             1.0   \n",
       "1                                             1.0   \n",
       "2                                             1.0   \n",
       "3                                             1.0   \n",
       "4                                             1.0   \n",
       "5                                             1.0   \n",
       "6                                             1.0   \n",
       "7                                             1.0   \n",
       "8                                             1.0   \n",
       "9                                             1.0   \n",
       "\n",
       "   address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "0                                       1.0              365.0   \n",
       "1                                       1.0              365.0   \n",
       "2                                       1.0              365.0   \n",
       "3                                       1.0              365.0   \n",
       "4                                       1.0              365.0   \n",
       "5                                       1.0              365.0   \n",
       "6                                       1.0              365.0   \n",
       "7                                       1.0              365.0   \n",
       "8                                       1.0              365.0   \n",
       "9                                       1.0              365.0   \n",
       "\n",
       "   address_count_14  address_count_7  address_count_0_by_30  \n",
       "0               1.0              1.0                   30.0  \n",
       "1               1.0              1.0                   30.0  \n",
       "2               1.0              1.0                   30.0  \n",
       "3               1.0              1.0                   30.0  \n",
       "4               1.0              1.0                   30.0  \n",
       "5               1.0              1.0                   30.0  \n",
       "6               1.0              1.0                   30.0  \n",
       "7               1.0              1.0                   30.0  \n",
       "8               1.0              1.0                   30.0  \n",
       "9               1.0              1.0                   30.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>500000.500000</td>\n",
       "      <td>0.014393</td>\n",
       "      <td>325.060480</td>\n",
       "      <td>1.046384</td>\n",
       "      <td>1.066381</td>\n",
       "      <td>1.028348</td>\n",
       "      <td>1.052878</td>\n",
       "      <td>1.042172</td>\n",
       "      <td>320.117207</td>\n",
       "      <td>1.054768</td>\n",
       "      <td>1.042577</td>\n",
       "      <td>29.358254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288675.278933</td>\n",
       "      <td>0.119104</td>\n",
       "      <td>99.097485</td>\n",
       "      <td>0.497036</td>\n",
       "      <td>0.701078</td>\n",
       "      <td>0.539675</td>\n",
       "      <td>0.641431</td>\n",
       "      <td>0.607350</td>\n",
       "      <td>104.836655</td>\n",
       "      <td>0.618082</td>\n",
       "      <td>0.585789</td>\n",
       "      <td>3.205310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250000.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>500000.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>750000.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Recnum           Fraud  fulladdress_day_since  \\\n",
       "count  1000000.000000  1000000.000000         1000000.000000   \n",
       "mean    500000.500000        0.014393             325.060480   \n",
       "std     288675.278933        0.119104              99.097485   \n",
       "min          1.000000        0.000000               0.000000   \n",
       "25%     250000.750000        0.000000             365.000000   \n",
       "50%     500000.500000        0.000000             365.000000   \n",
       "75%     750000.250000        0.000000             365.000000   \n",
       "max    1000000.000000        1.000000             365.000000   \n",
       "\n",
       "       name_dob_count_30  address_unique_count_for_name_homephone_60  \\\n",
       "count     1000000.000000                              1000000.000000   \n",
       "mean            1.046384                                    1.066381   \n",
       "std             0.497036                                    0.701078   \n",
       "min             1.000000                                    1.000000   \n",
       "25%             1.000000                                    1.000000   \n",
       "50%             1.000000                                    1.000000   \n",
       "75%             1.000000                                    1.000000   \n",
       "max            34.000000                                   30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "count                                1000000.000000   \n",
       "mean                                       1.028348   \n",
       "std                                        0.539675   \n",
       "min                                        1.000000   \n",
       "25%                                        1.000000   \n",
       "50%                                        1.000000   \n",
       "75%                                        1.000000   \n",
       "max                                       30.000000   \n",
       "\n",
       "       address_unique_count_for_homephone_name_dob_30  \\\n",
       "count                                  1000000.000000   \n",
       "mean                                         1.052878   \n",
       "std                                          0.641431   \n",
       "min                                          1.000000   \n",
       "25%                                          1.000000   \n",
       "50%                                          1.000000   \n",
       "75%                                          1.000000   \n",
       "max                                         30.000000   \n",
       "\n",
       "       address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "count                            1000000.000000     1000000.000000   \n",
       "mean                                   1.042172         320.117207   \n",
       "std                                    0.607350         104.836655   \n",
       "min                                    1.000000           0.000000   \n",
       "25%                                    1.000000         365.000000   \n",
       "50%                                    1.000000         365.000000   \n",
       "75%                                    1.000000         365.000000   \n",
       "max                                   30.000000         365.000000   \n",
       "\n",
       "       address_count_14  address_count_7  address_count_0_by_30  \n",
       "count    1000000.000000   1000000.000000         1000000.000000  \n",
       "mean           1.054768         1.042577              29.358254  \n",
       "std            0.618082         0.585789               3.205310  \n",
       "min            1.000000         1.000000               1.304348  \n",
       "25%            1.000000         1.000000              30.000000  \n",
       "50%            1.000000         1.000000              30.000000  \n",
       "75%            1.000000         1.000000              30.000000  \n",
       "max           30.000000        30.000000              30.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud\n",
       "0    0.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_save = vars['Recnum']\n",
    "Y_save = pd.DataFrame(vars.loc[:,'Fraud'])\n",
    "Y_save.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and truncate field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>325.060480</td>\n",
       "      <td>1.046384</td>\n",
       "      <td>1.066381</td>\n",
       "      <td>1.028348</td>\n",
       "      <td>1.052878</td>\n",
       "      <td>1.042172</td>\n",
       "      <td>320.117207</td>\n",
       "      <td>1.054768</td>\n",
       "      <td>1.042577</td>\n",
       "      <td>29.358254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>99.097485</td>\n",
       "      <td>0.497036</td>\n",
       "      <td>0.701078</td>\n",
       "      <td>0.539675</td>\n",
       "      <td>0.641431</td>\n",
       "      <td>0.607350</td>\n",
       "      <td>104.836655</td>\n",
       "      <td>0.618082</td>\n",
       "      <td>0.585789</td>\n",
       "      <td>3.205310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>365.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fulladdress_day_since  name_dob_count_30  \\\n",
       "count         1000000.000000     1000000.000000   \n",
       "mean              325.060480           1.046384   \n",
       "std                99.097485           0.497036   \n",
       "min                 0.000000           1.000000   \n",
       "25%               365.000000           1.000000   \n",
       "50%               365.000000           1.000000   \n",
       "75%               365.000000           1.000000   \n",
       "max               365.000000          34.000000   \n",
       "\n",
       "       address_unique_count_for_name_homephone_60  \\\n",
       "count                              1000000.000000   \n",
       "mean                                     1.066381   \n",
       "std                                      0.701078   \n",
       "min                                      1.000000   \n",
       "25%                                      1.000000   \n",
       "50%                                      1.000000   \n",
       "75%                                      1.000000   \n",
       "max                                     30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "count                                1000000.000000   \n",
       "mean                                       1.028348   \n",
       "std                                        0.539675   \n",
       "min                                        1.000000   \n",
       "25%                                        1.000000   \n",
       "50%                                        1.000000   \n",
       "75%                                        1.000000   \n",
       "max                                       30.000000   \n",
       "\n",
       "       address_unique_count_for_homephone_name_dob_30  \\\n",
       "count                                  1000000.000000   \n",
       "mean                                         1.052878   \n",
       "std                                          0.641431   \n",
       "min                                          1.000000   \n",
       "25%                                          1.000000   \n",
       "50%                                          1.000000   \n",
       "75%                                          1.000000   \n",
       "max                                         30.000000   \n",
       "\n",
       "       address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "count                            1000000.000000     1000000.000000   \n",
       "mean                                   1.042172         320.117207   \n",
       "std                                    0.607350         104.836655   \n",
       "min                                    1.000000           0.000000   \n",
       "25%                                    1.000000         365.000000   \n",
       "50%                                    1.000000         365.000000   \n",
       "75%                                    1.000000         365.000000   \n",
       "max                                   30.000000         365.000000   \n",
       "\n",
       "       address_count_14  address_count_7  address_count_0_by_30  \n",
       "count    1000000.000000   1000000.000000         1000000.000000  \n",
       "mean           1.054768         1.042577              29.358254  \n",
       "std            0.618082         0.585789               3.205310  \n",
       "min            1.000000         1.000000               1.304348  \n",
       "25%            1.000000         1.000000              30.000000  \n",
       "50%            1.000000         1.000000              30.000000  \n",
       "75%            1.000000         1.000000              30.000000  \n",
       "max           30.000000        30.000000              30.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_scaling = vars.drop(columns = ['Recnum','Fraud'])\n",
    "X_no_scaling.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to cap variables. For some problems it helps\n",
    "Clip = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.623209e-14</td>\n",
       "      <td>3.451346e-14</td>\n",
       "      <td>-8.867842e-14</td>\n",
       "      <td>1.657446e-14</td>\n",
       "      <td>-7.463379e-14</td>\n",
       "      <td>-3.191538e-14</td>\n",
       "      <td>-5.907877e-13</td>\n",
       "      <td>5.280565e-14</td>\n",
       "      <td>2.188792e-14</td>\n",
       "      <td>-6.455372e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.280209e+00</td>\n",
       "      <td>-9.332121e-02</td>\n",
       "      <td>-9.468412e-02</td>\n",
       "      <td>-5.252795e-02</td>\n",
       "      <td>-8.243749e-02</td>\n",
       "      <td>-6.943609e-02</td>\n",
       "      <td>-3.053486e+00</td>\n",
       "      <td>-8.860966e-02</td>\n",
       "      <td>-7.268319e-02</td>\n",
       "      <td>-8.752323e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.030326e-01</td>\n",
       "      <td>-9.332121e-02</td>\n",
       "      <td>-9.468412e-02</td>\n",
       "      <td>-5.252795e-02</td>\n",
       "      <td>-8.243749e-02</td>\n",
       "      <td>-6.943609e-02</td>\n",
       "      <td>4.281212e-01</td>\n",
       "      <td>-8.860966e-02</td>\n",
       "      <td>-7.268319e-02</td>\n",
       "      <td>2.002135e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.030326e-01</td>\n",
       "      <td>-9.332121e-02</td>\n",
       "      <td>-9.468412e-02</td>\n",
       "      <td>-5.252795e-02</td>\n",
       "      <td>-8.243749e-02</td>\n",
       "      <td>-6.943609e-02</td>\n",
       "      <td>4.281212e-01</td>\n",
       "      <td>-8.860966e-02</td>\n",
       "      <td>-7.268319e-02</td>\n",
       "      <td>2.002135e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.030326e-01</td>\n",
       "      <td>-9.332121e-02</td>\n",
       "      <td>-9.468412e-02</td>\n",
       "      <td>-5.252795e-02</td>\n",
       "      <td>-8.243749e-02</td>\n",
       "      <td>-6.943609e-02</td>\n",
       "      <td>4.281212e-01</td>\n",
       "      <td>-8.860966e-02</td>\n",
       "      <td>-7.268319e-02</td>\n",
       "      <td>2.002135e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.030326e-01</td>\n",
       "      <td>6.630026e+01</td>\n",
       "      <td>4.127016e+01</td>\n",
       "      <td>5.368356e+01</td>\n",
       "      <td>4.512894e+01</td>\n",
       "      <td>4.767899e+01</td>\n",
       "      <td>4.281212e-01</td>\n",
       "      <td>4.683076e+01</td>\n",
       "      <td>4.943321e+01</td>\n",
       "      <td>2.002135e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fulladdress_day_since  name_dob_count_30  \\\n",
       "count           1.000000e+06       1.000000e+06   \n",
       "mean           -4.623209e-14       3.451346e-14   \n",
       "std             1.000000e+00       1.000000e+00   \n",
       "min            -3.280209e+00      -9.332121e-02   \n",
       "25%             4.030326e-01      -9.332121e-02   \n",
       "50%             4.030326e-01      -9.332121e-02   \n",
       "75%             4.030326e-01      -9.332121e-02   \n",
       "max             4.030326e-01       6.630026e+01   \n",
       "\n",
       "       address_unique_count_for_name_homephone_60  \\\n",
       "count                                1.000000e+06   \n",
       "mean                                -8.867842e-14   \n",
       "std                                  1.000000e+00   \n",
       "min                                 -9.468412e-02   \n",
       "25%                                 -9.468412e-02   \n",
       "50%                                 -9.468412e-02   \n",
       "75%                                 -9.468412e-02   \n",
       "max                                  4.127016e+01   \n",
       "\n",
       "       fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "count                                  1.000000e+06   \n",
       "mean                                   1.657446e-14   \n",
       "std                                    1.000000e+00   \n",
       "min                                   -5.252795e-02   \n",
       "25%                                   -5.252795e-02   \n",
       "50%                                   -5.252795e-02   \n",
       "75%                                   -5.252795e-02   \n",
       "max                                    5.368356e+01   \n",
       "\n",
       "       address_unique_count_for_homephone_name_dob_30  \\\n",
       "count                                    1.000000e+06   \n",
       "mean                                    -7.463379e-14   \n",
       "std                                      1.000000e+00   \n",
       "min                                     -8.243749e-02   \n",
       "25%                                     -8.243749e-02   \n",
       "50%                                     -8.243749e-02   \n",
       "75%                                     -8.243749e-02   \n",
       "max                                      4.512894e+01   \n",
       "\n",
       "       address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "count                              1.000000e+06       1.000000e+06   \n",
       "mean                              -3.191538e-14      -5.907877e-13   \n",
       "std                                1.000000e+00       1.000000e+00   \n",
       "min                               -6.943609e-02      -3.053486e+00   \n",
       "25%                               -6.943609e-02       4.281212e-01   \n",
       "50%                               -6.943609e-02       4.281212e-01   \n",
       "75%                               -6.943609e-02       4.281212e-01   \n",
       "max                                4.767899e+01       4.281212e-01   \n",
       "\n",
       "       address_count_14  address_count_7  address_count_0_by_30  \n",
       "count      1.000000e+06     1.000000e+06           1.000000e+06  \n",
       "mean       5.280565e-14     2.188792e-14          -6.455372e-14  \n",
       "std        1.000000e+00     1.000000e+00           1.000000e+00  \n",
       "min       -8.860966e-02    -7.268319e-02          -8.752323e+00  \n",
       "25%       -8.860966e-02    -7.268319e-02           2.002135e-01  \n",
       "50%       -8.860966e-02    -7.268319e-02           2.002135e-01  \n",
       "75%       -8.860966e-02    -7.268319e-02           2.002135e-01  \n",
       "max        4.683076e+01     4.943321e+01           2.002135e-01  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push in any outlier values, then rescale\n",
    "X.clip(-1*Clip,Clip,inplace=True)\n",
    "# Now redo the zscaling after clipping\n",
    "X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate data into modeling (traintest) and out of time. Here I'm using the record number to do this separation.\n",
    "# you need to change this oot record number to whatever is appropriate for your data\n",
    "oot_recnum = 833507\n",
    "X_trntst = X[0:oot_recnum]\n",
    "Y_trntst = Y_save[0:oot_recnum]\n",
    "X_oot = X[oot_recnum:]\n",
    "Y_oot = Y_save[oot_recnum:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve a linear regression with ridge and lasso regularization and watch how the variable weights evolve with the regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(2,9,30)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "coefs = []\n",
    "for a in alphas: \n",
    "    ridge.set_params(alpha=a) \n",
    "    ridge.fit(X_trn,Y_trn.values.ravel()) \n",
    "    coefs.append(ridge.coef_) \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 488 ms, sys: 571 ms, total: 1.06 s\n",
      "Wall time: 535 ms\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "ax = plt.gca() # Get the current Axes instance\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('lambda') \n",
    "plt.ylabel('standadized coef') \n",
    "plt.title('Ridge')\n",
    "plt.savefig('ridge.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(-5,0,30)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: []\n",
      "CPU times: user 1min 24s, sys: 48.5 s, total: 2min 12s\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# sometimes this cell takes a long time\n",
    "lasso = Lasso(max_iter=10000) \n",
    "coefs = [] \n",
    "for a in alphas: \n",
    "    lasso.set_params(alpha=a) \n",
    "    lasso.fit(X_trn,Y_trn.values.ravel()) \n",
    "    coefs.append(lasso.coef_) \n",
    "# print('Shape:',np.shape(coefs)\n",
    "print('Selected Features:', list(vars.columns[np.where(lasso.coef_!=0)[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = plt.gca() # Get the current Axes instance \n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('standerdized coef') \n",
    "plt.title('Lasso')\n",
    "plt.legend()\n",
    "plt.savefig('lasso.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_trntst.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trntst_save = X_trntst.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components = .999, svd_solver = 'full')\n",
    "pca.fit(X_trntst)\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('Number of components minus 1')\n",
    "plt.ylabel('PC variance')\n",
    "plt.xticks(np.arange(0, len(X_trntst.columns), step=2))\n",
    "plt.axhline(y=0,xmin=0,xmax=len(X_trntst.columns))\n",
    "X_trntst = X_trntst_save.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.339775</td>\n",
       "      <td>0.503031</td>\n",
       "      <td>0.06892</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.030222</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.339775</td>\n",
       "      <td>0.503031</td>\n",
       "      <td>0.06892</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.030222</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.339775</td>\n",
       "      <td>0.503031</td>\n",
       "      <td>0.06892</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.030222</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.339775</td>\n",
       "      <td>0.503031</td>\n",
       "      <td>0.06892</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.030222</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.339775</td>\n",
       "      <td>0.503031</td>\n",
       "      <td>0.06892</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.030222</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2      PC3       PC4       PC5       PC6\n",
       "0 -0.339775  0.503031  0.06892 -0.077396 -0.030222  0.009852\n",
       "1 -0.339775  0.503031  0.06892 -0.077396 -0.030222  0.009852\n",
       "2 -0.339775  0.503031  0.06892 -0.077396 -0.030222  0.009852\n",
       "3 -0.339775  0.503031  0.06892 -0.077396 -0.030222  0.009852\n",
       "4 -0.339775  0.503031  0.06892 -0.077396 -0.030222  0.009852"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We look at the above picture, select how many PCs we want to keep, and then redo the PCA with just this many PCs\n",
    "pca = PCA(n_components = 6, svd_solver = 'full')\n",
    "princ_comps = pca.fit_transform(X_trntst)\n",
    "X_trntst_pca = pd.DataFrame(princ_comps, columns = ['PC' + str(i) for i in range(1, pca.n_components_+1)])\n",
    "X_trntst_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>833507</th>\n",
       "      <td>0.362704</td>\n",
       "      <td>-2.257233</td>\n",
       "      <td>-1.049263</td>\n",
       "      <td>1.246642</td>\n",
       "      <td>0.248469</td>\n",
       "      <td>0.056855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833508</th>\n",
       "      <td>-0.339775</td>\n",
       "      <td>0.503031</td>\n",
       "      <td>0.068920</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.030222</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833509</th>\n",
       "      <td>2.384934</td>\n",
       "      <td>-5.883519</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>-1.403144</td>\n",
       "      <td>-1.226504</td>\n",
       "      <td>0.265268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833510</th>\n",
       "      <td>-0.339775</td>\n",
       "      <td>0.503031</td>\n",
       "      <td>0.068920</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.030222</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833511</th>\n",
       "      <td>-0.339775</td>\n",
       "      <td>0.503031</td>\n",
       "      <td>0.068920</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.030222</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3       PC4       PC5       PC6\n",
       "833507  0.362704 -2.257233 -1.049263  1.246642  0.248469  0.056855\n",
       "833508 -0.339775  0.503031  0.068920 -0.077396 -0.030222  0.009852\n",
       "833509  2.384934 -5.883519  0.874989 -1.403144 -1.226504  0.265268\n",
       "833510 -0.339775  0.503031  0.068920 -0.077396 -0.030222  0.009852\n",
       "833511 -0.339775  0.503031  0.068920 -0.077396 -0.030222  0.009852"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "princ_comps = pca.transform(X_oot)\n",
    "X_oot_orig_pca = pd.DataFrame(princ_comps, columns = ['PC' + str(i) for i in range(1, pca.n_components_+1)],index=X_oot.index)\n",
    "X_oot_orig_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>833507.000000</td>\n",
       "      <td>833507.000000</td>\n",
       "      <td>833507.000000</td>\n",
       "      <td>833507.000000</td>\n",
       "      <td>833507.000000</td>\n",
       "      <td>833507.000000</td>\n",
       "      <td>833507.000000</td>\n",
       "      <td>833507.000000</td>\n",
       "      <td>833507.000000</td>\n",
       "      <td>833507.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.031522</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.031615</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.981263</td>\n",
       "      <td>0.979550</td>\n",
       "      <td>0.996756</td>\n",
       "      <td>1.013675</td>\n",
       "      <td>1.002736</td>\n",
       "      <td>1.008244</td>\n",
       "      <td>0.983233</td>\n",
       "      <td>1.007653</td>\n",
       "      <td>1.011013</td>\n",
       "      <td>0.997512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>-0.088610</td>\n",
       "      <td>-0.072683</td>\n",
       "      <td>-8.752323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.088610</td>\n",
       "      <td>-0.072683</td>\n",
       "      <td>0.200213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.088610</td>\n",
       "      <td>-0.072683</td>\n",
       "      <td>0.200213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.088610</td>\n",
       "      <td>-0.072683</td>\n",
       "      <td>0.200213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>66.300262</td>\n",
       "      <td>41.270156</td>\n",
       "      <td>53.683556</td>\n",
       "      <td>45.128940</td>\n",
       "      <td>47.678988</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>46.830762</td>\n",
       "      <td>49.433212</td>\n",
       "      <td>0.200213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fulladdress_day_since  name_dob_count_30  \\\n",
       "count          833507.000000      833507.000000   \n",
       "mean                0.031522          -0.001708   \n",
       "std                 0.981263           0.979550   \n",
       "min                -3.280209          -0.093321   \n",
       "25%                 0.403033          -0.093321   \n",
       "50%                 0.403033          -0.093321   \n",
       "75%                 0.403033          -0.093321   \n",
       "max                 0.403033          66.300262   \n",
       "\n",
       "       address_unique_count_for_name_homephone_60  \\\n",
       "count                               833507.000000   \n",
       "mean                                    -0.000377   \n",
       "std                                      0.996756   \n",
       "min                                     -0.094684   \n",
       "25%                                     -0.094684   \n",
       "50%                                     -0.094684   \n",
       "75%                                     -0.094684   \n",
       "max                                     41.270156   \n",
       "\n",
       "       fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "count                                 833507.000000   \n",
       "mean                                       0.001320   \n",
       "std                                        1.013675   \n",
       "min                                       -0.052528   \n",
       "25%                                       -0.052528   \n",
       "50%                                       -0.052528   \n",
       "75%                                       -0.052528   \n",
       "max                                       53.683556   \n",
       "\n",
       "       address_unique_count_for_homephone_name_dob_30  \\\n",
       "count                                   833507.000000   \n",
       "mean                                         0.000348   \n",
       "std                                          1.002736   \n",
       "min                                         -0.082437   \n",
       "25%                                         -0.082437   \n",
       "50%                                         -0.082437   \n",
       "75%                                         -0.082437   \n",
       "max                                         45.128940   \n",
       "\n",
       "       address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "count                             833507.000000      833507.000000   \n",
       "mean                                   0.000852           0.031615   \n",
       "std                                    1.008244           0.983233   \n",
       "min                                   -0.069436          -3.053486   \n",
       "25%                                   -0.069436           0.428121   \n",
       "50%                                   -0.069436           0.428121   \n",
       "75%                                   -0.069436           0.428121   \n",
       "max                                   47.678988           0.428121   \n",
       "\n",
       "       address_count_14  address_count_7  address_count_0_by_30  \n",
       "count     833507.000000    833507.000000          833507.000000  \n",
       "mean           0.000682         0.001052               0.000987  \n",
       "std            1.007653         1.011013               0.997512  \n",
       "min           -0.088610        -0.072683              -8.752323  \n",
       "25%           -0.088610        -0.072683               0.200213  \n",
       "50%           -0.088610        -0.072683               0.200213  \n",
       "75%           -0.088610        -0.072683               0.200213  \n",
       "max           46.830762        49.433212               0.200213  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trntst.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.048785</td>\n",
       "      <td>-0.229548</td>\n",
       "      <td>-0.079726</td>\n",
       "      <td>0.099097</td>\n",
       "      <td>0.030212</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.369841</td>\n",
       "      <td>1.519470</td>\n",
       "      <td>1.081792</td>\n",
       "      <td>0.793787</td>\n",
       "      <td>0.479536</td>\n",
       "      <td>0.256440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.339775</td>\n",
       "      <td>-17.177066</td>\n",
       "      <td>-1.525646</td>\n",
       "      <td>-13.721778</td>\n",
       "      <td>-4.483085</td>\n",
       "      <td>-2.943942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.339775</td>\n",
       "      <td>-0.336583</td>\n",
       "      <td>0.068920</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.030222</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.339775</td>\n",
       "      <td>0.503031</td>\n",
       "      <td>0.068920</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.030222</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.115743</td>\n",
       "      <td>0.503031</td>\n",
       "      <td>0.068920</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.014033</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>112.094993</td>\n",
       "      <td>28.411235</td>\n",
       "      <td>52.738243</td>\n",
       "      <td>13.046666</td>\n",
       "      <td>25.192169</td>\n",
       "      <td>11.114122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PC1            PC2            PC3            PC4  \\\n",
       "count  166493.000000  166493.000000  166493.000000  166493.000000   \n",
       "mean        0.048785      -0.229548      -0.079726       0.099097   \n",
       "std         2.369841       1.519470       1.081792       0.793787   \n",
       "min        -0.339775     -17.177066      -1.525646     -13.721778   \n",
       "25%        -0.339775      -0.336583       0.068920      -0.077396   \n",
       "50%        -0.339775       0.503031       0.068920      -0.077396   \n",
       "75%        -0.115743       0.503031       0.068920      -0.077396   \n",
       "max       112.094993      28.411235      52.738243      13.046666   \n",
       "\n",
       "                 PC5            PC6  \n",
       "count  166493.000000  166493.000000  \n",
       "mean        0.030212       0.000211  \n",
       "std         0.479536       0.256440  \n",
       "min        -4.483085      -2.943942  \n",
       "25%        -0.030222       0.009852  \n",
       "50%        -0.030222       0.009852  \n",
       "75%        -0.014033       0.009852  \n",
       "max        25.192169      11.114122  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_oot_orig_pca.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# zscale the PCs\n",
    "mean = X_trntst_pca.mean()\n",
    "stdev = X_trntst_pca.std()\n",
    "X_trntst_pca = (X_trntst_pca - mean)/stdev\n",
    "X_oot_orig_pca = (X_oot_orig_pca - mean)/stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.335070e+05</td>\n",
       "      <td>8.335070e+05</td>\n",
       "      <td>8.335070e+05</td>\n",
       "      <td>8.335070e+05</td>\n",
       "      <td>8.335070e+05</td>\n",
       "      <td>8.335070e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.127105e-13</td>\n",
       "      <td>2.510007e-12</td>\n",
       "      <td>-1.092351e-13</td>\n",
       "      <td>4.067178e-13</td>\n",
       "      <td>-4.607697e-13</td>\n",
       "      <td>-2.409311e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.368752e-01</td>\n",
       "      <td>-1.482246e+01</td>\n",
       "      <td>-1.627442e+00</td>\n",
       "      <td>-1.670794e+01</td>\n",
       "      <td>-1.125181e+01</td>\n",
       "      <td>-1.243141e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.368752e-01</td>\n",
       "      <td>3.503039e-01</td>\n",
       "      <td>7.226082e-02</td>\n",
       "      <td>-1.071123e-01</td>\n",
       "      <td>-7.245114e-02</td>\n",
       "      <td>4.274045e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.368752e-01</td>\n",
       "      <td>3.503039e-01</td>\n",
       "      <td>7.226082e-02</td>\n",
       "      <td>-1.071123e-01</td>\n",
       "      <td>-7.245114e-02</td>\n",
       "      <td>4.274045e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.368752e-01</td>\n",
       "      <td>3.503039e-01</td>\n",
       "      <td>7.226082e-02</td>\n",
       "      <td>-1.071123e-01</td>\n",
       "      <td>-7.245114e-02</td>\n",
       "      <td>4.274045e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.507641e+01</td>\n",
       "      <td>2.005348e+01</td>\n",
       "      <td>6.515550e+01</td>\n",
       "      <td>2.110023e+01</td>\n",
       "      <td>6.036486e+01</td>\n",
       "      <td>6.637075e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PC1           PC2           PC3           PC4           PC5  \\\n",
       "count  8.335070e+05  8.335070e+05  8.335070e+05  8.335070e+05  8.335070e+05   \n",
       "mean   3.127105e-13  2.510007e-12 -1.092351e-13  4.067178e-13 -4.607697e-13   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.368752e-01 -1.482246e+01 -1.627442e+00 -1.670794e+01 -1.125181e+01   \n",
       "25%   -1.368752e-01  3.503039e-01  7.226082e-02 -1.071123e-01 -7.245114e-02   \n",
       "50%   -1.368752e-01  3.503039e-01  7.226082e-02 -1.071123e-01 -7.245114e-02   \n",
       "75%   -1.368752e-01  3.503039e-01  7.226082e-02 -1.071123e-01 -7.245114e-02   \n",
       "max    4.507641e+01  2.005348e+01  6.515550e+01  2.110023e+01  6.036486e+01   \n",
       "\n",
       "                PC6  \n",
       "count  8.335070e+05  \n",
       "mean  -2.409311e-14  \n",
       "std    1.000000e+00  \n",
       "min   -1.243141e+01  \n",
       "25%    4.274045e-02  \n",
       "50%    4.274045e-02  \n",
       "75%    4.274045e-02  \n",
       "max    6.637075e+01  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trntst_pca.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.019652</td>\n",
       "      <td>-0.159854</td>\n",
       "      <td>-0.083590</td>\n",
       "      <td>0.137145</td>\n",
       "      <td>0.072425</td>\n",
       "      <td>0.000913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.954668</td>\n",
       "      <td>1.058138</td>\n",
       "      <td>1.134225</td>\n",
       "      <td>1.098562</td>\n",
       "      <td>1.149575</td>\n",
       "      <td>1.112487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.136875</td>\n",
       "      <td>-11.961871</td>\n",
       "      <td>-1.599592</td>\n",
       "      <td>-18.990260</td>\n",
       "      <td>-10.747141</td>\n",
       "      <td>-12.771391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.136875</td>\n",
       "      <td>-0.234392</td>\n",
       "      <td>0.072261</td>\n",
       "      <td>-0.107112</td>\n",
       "      <td>-0.072451</td>\n",
       "      <td>0.042740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.136875</td>\n",
       "      <td>0.350304</td>\n",
       "      <td>0.072261</td>\n",
       "      <td>-0.107112</td>\n",
       "      <td>-0.072451</td>\n",
       "      <td>0.042740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.046626</td>\n",
       "      <td>0.350304</td>\n",
       "      <td>0.072261</td>\n",
       "      <td>-0.107112</td>\n",
       "      <td>-0.033640</td>\n",
       "      <td>0.042740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.156376</td>\n",
       "      <td>19.785191</td>\n",
       "      <td>55.294400</td>\n",
       "      <td>18.055938</td>\n",
       "      <td>60.392294</td>\n",
       "      <td>48.215223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PC1            PC2            PC3            PC4  \\\n",
       "count  166493.000000  166493.000000  166493.000000  166493.000000   \n",
       "mean        0.019652      -0.159854      -0.083590       0.137145   \n",
       "std         0.954668       1.058138       1.134225       1.098562   \n",
       "min        -0.136875     -11.961871      -1.599592     -18.990260   \n",
       "25%        -0.136875      -0.234392       0.072261      -0.107112   \n",
       "50%        -0.136875       0.350304       0.072261      -0.107112   \n",
       "75%        -0.046626       0.350304       0.072261      -0.107112   \n",
       "max        45.156376      19.785191      55.294400      18.055938   \n",
       "\n",
       "                 PC5            PC6  \n",
       "count  166493.000000  166493.000000  \n",
       "mean        0.072425       0.000913  \n",
       "std         1.149575       1.112487  \n",
       "min       -10.747141     -12.771391  \n",
       "25%        -0.072451       0.042740  \n",
       "50%        -0.072451       0.042740  \n",
       "75%        -0.033640       0.042740  \n",
       "max        60.392294      48.215223  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_oot_orig_pca.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(833507, 6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trntst_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166493, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_oot_orig_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample the larger class if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0144053979150745\n",
      "(23841, 10) 23841\n"
     ]
    }
   ],
   "source": [
    "# set the ratio of goods to bads that you would like. This next line is the ratio of goods to bads that you want for modeling\n",
    "sample_ratio_desired = 1\n",
    "\n",
    "temp = X_trntst.copy()\n",
    "temp['Fraud'] = Y_trntst['Fraud']\n",
    "temp.head()\n",
    "goods = temp[temp['Fraud']==0]\n",
    "bads = temp[temp['Fraud']==1]\n",
    "actual_bad_fraction = len(bads)/len(temp)\n",
    "actual_good_fraction = 1 - actual_bad_fraction\n",
    "print(actual_bad_fraction)\n",
    "fraction = sample_ratio_desired * actual_bad_fraction\n",
    "goods_sampled = goods.sample(frac = fraction)\n",
    "all_sampled = pd.concat([goods_sampled,bads])\n",
    "all_sampled.sort_index(inplace=True)\n",
    "Y_trntst_sampled = pd.DataFrame(all_sampled['Fraud'])\n",
    "X_trntst_sampled = all_sampled.drop(columns=['Fraud'])\n",
    "del [temp,goods,bads,all_sampled]\n",
    "gc.collect()\n",
    "print(X_trntst_sampled.shape,len(Y_trntst_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "niter = 0\n",
    "nitermax = 5\n",
    "X_oot_orig = X_oot.copy()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can comment in/out any of these model cells and just explore one model type. You can also just rerun that single cell multiple times (hit shift-enter on that cell) as you manually explore different model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modeling_output = pd.DataFrame(columns=['Model','Trn','Tst','OOT'],index=range(1000))\n",
    "counter = 0\n",
    "model_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.49279504584970824 0.48282548476454296 0.47569153394803015\n",
      "1 0.49229666786098175 0.4834892680242157 0.4752724224643755\n",
      "2 0.4781567923399162 0.4786418400876232 0.46353730092204526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuachang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.4748192913852352 0.48710762331838564 0.46353730092204526\n",
      "4 0.4937724550898204 0.47607328411266064 0.4740150880134116\n",
      "trn    0.486368\n",
      "tst    0.481628\n",
      "oot    0.470411\n",
      "dtype: float64\n",
      "CPU times: user 22.6 s, sys: 35.5 s, total: 58.2 s\n",
      "Wall time: 8.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = LogisticRegression(max_iter=100, penalty = 'l2', C = 0.1, solver = 'lbfgs', l1_ratio = None)\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['log reg',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5190385530699667 0.5076325284485151 0.4899413243922883\n",
      "1 0.527047913446677 0.5283648498331479 0.5033528918692373\n",
      "2 0.5288699964576692 0.5257207461842849 0.5016764459346186\n",
      "3 0.5314726840855107 0.5210482297184277 0.5008382229673093\n",
      "4 0.5211217183770883 0.5122690929142542 0.49497066219614416\n",
      "trn    0.525510\n",
      "tst    0.519007\n",
      "oot    0.498156\n",
      "dtype: float64\n",
      "CPU times: user 2.48 s, sys: 160 ms, total: 2.64 s\n",
      "Wall time: 2.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Single DT\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = DecisionTreeClassifier(max_depth=100,min_samples_leaf=300,min_samples_split=700, max_features = 10)\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['DT',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "\n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5454981992797119 0.5121022572749524 0.501257334450964\n",
      "1 0.544164977947312 0.5157545605306799 0.5\n",
      "2 0.5446194225721784 0.5161379310344828 0.501257334450964\n",
      "3 0.544243577545195 0.5148652403445402 0.5\n",
      "4 0.5428029404790136 0.5186118108032466 0.5016764459346186\n",
      "trn    0.544266\n",
      "tst    0.515494\n",
      "oot    0.500838\n",
      "dtype: float64\n",
      "CPU times: user 2min 20s, sys: 857 ms, total: 2min 21s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RF\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100,max_depth=30,min_samples_split=50,min_samples_leaf=5,max_features=10)\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['RF',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5375311277125578 0.5170677112479015 0.5050293378038558\n",
      "1 0.5361702127659574 0.5176205243868057 0.5050293378038558\n",
      "2 0.5349892524480535 0.5172034131571703 0.5054484492875104\n",
      "3 0.5346663511594889 0.5198312236286919 0.5050293378038558\n",
      "4 0.5389307499102978 0.5095995611629183 0.5020955574182733\n",
      "trn    0.536458\n",
      "tst    0.516264\n",
      "oot    0.504526\n",
      "dtype: float64\n",
      "CPU times: user 12min 29s, sys: 2min 22s, total: 14min 51s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LGBM\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = lgb.LGBMClassifier(n_estimators=500, num_leaves=100, max_depth = 50)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['LGBM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5230041395623891 0.5318130630630631 0.5054484492875104\n",
      "1 0.519853462538407 0.5421720733427362 0.5046102263202011\n",
      "2 0.530288576198426 0.5208505937586302 0.5075440067057837\n",
      "3 0.5216821539194663 0.5399944644339884 0.508382229673093\n",
      "4 0.5283086909484312 0.5238611713665944 0.5054484492875104\n",
      "trn    0.524627\n",
      "tst    0.531738\n",
      "oot    0.506287\n",
      "dtype: float64\n",
      "CPU times: user 5min 8s, sys: 5min 39s, total: 10min 47s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NN\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(20,20,20), activation = 'relu', alpha = 0.01, learning_rate = 'adaptive', solver = 'lbfgs', learning_rate_init = 0.01)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['NN',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5767065446868402 0.5731111749497271 0.5507124895222129\n",
      "1 0.568895279175653 0.5714285714285714 0.5423302598491199\n",
      "2 0.566888045540797 0.566993006993007 0.5339480301760269\n",
      "3 0.5845347313237221 0.5902047592695074 0.5611902766135792\n",
      "4 0.57956186807896 0.5844822925114896 0.5540653813914501\n",
      "trn    0.575317\n",
      "tst    0.577244\n",
      "oot    0.548449\n",
      "dtype: float64\n",
      "CPU times: user 1min 2s, sys: 504 ms, total: 1min 2s\n",
      "Wall time: 57.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NN on pc's\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_pca, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(2))\n",
    "\n",
    "    X_oot = X_oot_orig_pca.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['NN_PCs',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5291800930898676 0.5107497243660419 0.5\n",
      "1 0.521796093377799 0.527277762392689 0.5020955574182733\n",
      "2 0.5268131348925112 0.5255577520474443 0.5016764459346186\n",
      "3 0.5267430754536772 0.5163866703387496 0.5008382229673093\n",
      "4 0.5256758352024554 0.5209276018099548 0.5008382229673093\n",
      "trn    0.526042\n",
      "tst    0.520180\n",
      "oot    0.501090\n",
      "dtype: float64\n",
      "CPU times: user 12.5 s, sys: 147 ms, total: 12.7 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# GBC\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = GradientBoostingClassifier(n_estimators=10, max_depth=6)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['GBC',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "catboost/private/libs/options/catboost_options.cpp:968: max_leaves option works only with lossguide tree growing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5126\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5128\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   5129\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5130\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2337\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2339\u001b[0;31m         train_params = self._prepare_train_params(\n\u001b[0m\u001b[1;32m   2340\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m             \u001b[0mpairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[0m_check_param_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_params_type_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m         \u001b[0m_check_train_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval_fraction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: catboost/private/libs/options/catboost_options.cpp:968: max_leaves option works only with lossguide tree growing"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Catboost\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = CatBoostClassifier(n_estimators = 20, max_depth = 2, num_leaves = 2)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['cat boost',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.41842258682435\n",
      "0 0.5964853835262763 0.5964853835262763 0.5716680637049455\n",
      "1 0.5957358207712168 0.5957358207712168 0.5720871751886002\n",
      "2 0.5964020987757142 0.5964020987757142 0.5716680637049455\n",
      "3 0.5960689597734655 0.5960689597734655 0.5720871751886002\n",
      "4 0.5959856750229033 0.5959856750229033 0.5704107292539815\n",
      "trn    0.596136\n",
      "tst    0.596136\n",
      "oot    0.571584\n",
      "dtype: float64\n",
      "CPU times: user 2.57 s, sys: 596 ms, total: 3.17 s\n",
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NOTE this cell has been substantially modified to evaluate a sampled trn/tst data set. \n",
    "# Only use this cell if you do downsampling of the goods.\n",
    "# each good needs to have a weight of (1-actual_ratio)/sample_ratio_desired\n",
    "# it's hard to get the correct FDR@3% for the actual train and test, so I just use the original trntst after the model is built for evaluation\n",
    "\n",
    "xmult = actual_good_fraction / (actual_bad_fraction * sample_ratio_desired)\n",
    "print(xmult)\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_sampled, Y_trntst_sampled, test_size = .3)\n",
    "\n",
    "    model = CatBoostClassifier(verbose=0, max_depth=2, iterations=5)\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())  \n",
    "    \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn = X_trntst.copy()\n",
    "    Y_trn = Y_trntst.copy()\n",
    "    X_tst = X_trntst.copy()\n",
    "    Y_tst = Y_trntst.copy()\n",
    "\n",
    "\n",
    "    predictions = model.predict_proba(X_trntst)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trntst['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_trntst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_trntst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['cat boost_sampled',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5408685306365258 0.5399777901166019 0.5134115674769488\n",
      "1 0.5399881164587047 0.5473273942093542 0.5134115674769488\n",
      "2 0.5566714490674318 0.5479000823497118 0.5272422464375524\n",
      "3 0.5439153439153439 0.5405482581382067 0.5142497904442582\n",
      "4 0.5694162588038677 0.5589531680440771 0.5393964794635373\n",
      "trn    0.550172\n",
      "tst    0.546941\n",
      "oot    0.521542\n",
      "dtype: float64\n",
      "CPU times: user 4.67 s, sys: 306 ms, total: 4.98 s\n",
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Catboost on pc's\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_pca, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = CatBoostClassifier(verbose=0, max_depth=2, iterations=5)\n",
    "\n",
    "\n",
    "    X_oot = X_oot_orig_pca.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['cat boost_PCs',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5559905100830368 0.5457086944366788 0.519279128248114\n",
      "1 0.5557547508067407 0.5464285714285714 0.519279128248114\n",
      "2 0.5499702911467618 0.5601336302895323 0.519279128248114\n",
      "3 0.5525876460767947 0.5526097763048882 0.519279128248114\n",
      "4 0.5505590958278226 0.5582655826558266 0.519279128248114\n",
      "trn    0.552972\n",
      "tst    0.552629\n",
      "oot    0.519279\n",
      "dtype: float64\n",
      "CPU times: user 1.53 s, sys: 246 ms, total: 1.77 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# unsupervised model using pc's. \n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_pca, Y_trntst, test_size = .3)\n",
    "\n",
    "    X_oot = X_oot_orig_pca.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    pow = 2\n",
    "    oop = 1/pow\n",
    "    predictions = ((X_trn.abs()**pow).sum(axis=1))**oop\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = ((X_tst.abs()**pow).sum(axis=1))**oop\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = ((X_oot.abs()**pow).sum(axis=1))**oop\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['unsupervised outliers',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:00:08] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0 0.5289236605026079 0.5270232427891347 0.5058675607711651\n",
      "[20:00:12] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.528441879637263 0.5216154721274175 0.5033528918692373\n",
      "[20:00:16] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2 0.530288576198426 0.5222314277823805 0.5062866722548198\n",
      "[20:00:20] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "3 0.5252055774043618 0.536504424778761 0.5062866722548198\n",
      "[20:00:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "4 0.5317932841152655 0.5184261568301468 0.5075440067057837\n",
      "trn    0.528931\n",
      "tst    0.525160\n",
      "oot    0.505868\n",
      "dtype: float64\n",
      "CPU times: user 54 s, sys: 21.1 s, total: 1min 15s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# XGB\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = xgb.XGBClassifier(n_estimators=20, max_depth=6)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['XGB',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Knn\n",
    "# # Knn can be very slow with a lot of records.\n",
    "\n",
    "# FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = KNeighborsClassifier(n_neighbors=50) \n",
    "    \n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*0.03))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*0.03))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*0.03))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['Knn',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR3.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # SVM\n",
    "# # SVM can be very slow. It scales like the # training records cubed\n",
    "\n",
    "# FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = svm.SVC(\n",
    "#         C=.1, \n",
    "# #         gamma=100,\n",
    "# #         kernel='linear',\n",
    "#         kernel='poly',\n",
    "#         probability=True)\n",
    "    \n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*0.03))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*0.03))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*0.03))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['SVM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR3.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Trn</th>\n",
       "      <th>Tst</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.488258</td>\n",
       "      <td>0.488115</td>\n",
       "      <td>0.473596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.49388</td>\n",
       "      <td>0.473831</td>\n",
       "      <td>0.473177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.491115</td>\n",
       "      <td>0.481226</td>\n",
       "      <td>0.474853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.486451</td>\n",
       "      <td>0.491511</td>\n",
       "      <td>0.472758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.485724</td>\n",
       "      <td>0.493474</td>\n",
       "      <td>0.473596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.46122</td>\n",
       "      <td>0.454776</td>\n",
       "      <td>0.443839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.45288</td>\n",
       "      <td>0.479878</td>\n",
       "      <td>0.443839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.460677</td>\n",
       "      <td>0.459751</td>\n",
       "      <td>0.443839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.4568</td>\n",
       "      <td>0.468584</td>\n",
       "      <td>0.443839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.463366</td>\n",
       "      <td>0.448345</td>\n",
       "      <td>0.443839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.479268</td>\n",
       "      <td>0.479109</td>\n",
       "      <td>0.464795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.492264</td>\n",
       "      <td>0.497087</td>\n",
       "      <td>0.476111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.495103</td>\n",
       "      <td>0.50564</td>\n",
       "      <td>0.479883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.475502</td>\n",
       "      <td>0.484474</td>\n",
       "      <td>0.465633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.467568</td>\n",
       "      <td>0.484611</td>\n",
       "      <td>0.461442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.512258</td>\n",
       "      <td>0.510928</td>\n",
       "      <td>0.489522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.511003</td>\n",
       "      <td>0.5173</td>\n",
       "      <td>0.49078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.510939</td>\n",
       "      <td>0.518973</td>\n",
       "      <td>0.49078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.509849</td>\n",
       "      <td>0.516707</td>\n",
       "      <td>0.489522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.514499</td>\n",
       "      <td>0.507589</td>\n",
       "      <td>0.489522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model       Trn       Tst       OOT\n",
       "0   log reg  0.488258  0.488115  0.473596\n",
       "1   log reg   0.49388  0.473831  0.473177\n",
       "2   log reg  0.491115  0.481226  0.474853\n",
       "3   log reg  0.486451  0.491511  0.472758\n",
       "4   log reg  0.485724  0.493474  0.473596\n",
       "5        DT   0.46122  0.454776  0.443839\n",
       "6        DT   0.45288  0.479878  0.443839\n",
       "7        DT  0.460677  0.459751  0.443839\n",
       "8        DT    0.4568  0.468584  0.443839\n",
       "9        DT  0.463366  0.448345  0.443839\n",
       "10       RF  0.479268  0.479109  0.464795\n",
       "11       RF  0.492264  0.497087  0.476111\n",
       "12       RF  0.495103   0.50564  0.479883\n",
       "13       RF  0.475502  0.484474  0.465633\n",
       "14       RF  0.467568  0.484611  0.461442\n",
       "15     LGBM  0.512258  0.510928  0.489522\n",
       "16     LGBM  0.511003    0.5173   0.49078\n",
       "17     LGBM  0.510939  0.518973   0.49078\n",
       "18     LGBM  0.509849  0.516707  0.489522\n",
       "19     LGBM  0.514499  0.507589  0.489522"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Modeling_output.dropna()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.488258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.49388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.491115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.486451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.485724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Type     Value\n",
       "0  log reg  Trn  0.488258\n",
       "1  log reg  Trn   0.49388\n",
       "2  log reg  Trn  0.491115\n",
       "3  log reg  Trn  0.486451\n",
       "4  log reg  Trn  0.485724"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unpivot = df.melt( id_vars='Model', value_vars=['Trn','Tst','OOT'], var_name=['Type'], value_name='Value')\n",
    "df_unpivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.488258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.49388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.491115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.486451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.485724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Type     Value\n",
       "0  log reg  Trn  0.488258\n",
       "1  log reg  Trn   0.49388\n",
       "2  log reg  Trn  0.491115\n",
       "3  log reg  Trn  0.486451\n",
       "4  log reg  Trn  0.485724"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare = df_unpivot[(df_unpivot['Type']=='Trn') | (df_unpivot['Type']=='Tst') | (df_unpivot['Type']=='OOT')]\n",
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataError",
     "evalue": "No numeric types to aggregate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-caf15c9d1138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Trn'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Tst'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'OOT'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_mangle_lambdas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/aggregation.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(obj, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAggFuncTypeDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0magg_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# we require a list, but not an 'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/aggregation.py\u001b[0m in \u001b[0;36magg_dict_like\u001b[0;34m(obj, arg, _axis)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;31m# key used for column selection and output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;31m# set the final keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/aggregation.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;31m# key used for column selection and output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;31m# set the final keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;31m# but not the class list / tuple itself.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_mangle_lambdas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_multiple_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrelabeling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_aggregate_multiple_funcs\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutputKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, numeric_only)\u001b[0m\n\u001b[1;32m   1494\u001b[0m         \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m         \"\"\"\n\u001b[0;32m-> 1496\u001b[0;31m         return self._cython_agg_general(\n\u001b[0m\u001b[1;32m   1497\u001b[0m             \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No numeric types to aggregate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_aggregated_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataError\u001b[0m: No numeric types to aggregate"
     ]
    }
   ],
   "source": [
    "output = df.groupby('Model').agg({'Trn':['mean','std'],'Tst':['mean','std'],'OOT':['mean','std']})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,15))\n",
    "ax = sns.boxplot(x='Model',y='Value',hue='Type', data=df_compare, palette=['navy','r','g'])\n",
    "\n",
    "plt.ylim(.5,.7)\n",
    "plt.ylabel('Score (FDR3%)')\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('modeling.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:05:33.669446\n"
     ]
    }
   ],
   "source": [
    "print('duration: ', datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL MODEL SECTION (PAUSE HERE; DELETE TITLE AFTER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the notebook makes the tables for your final model of choice. You need to run that final model only once (no CV). If you want you can run the below cell over and over by itself until it gives you a model you like (due to the stochastic nature of some ML algorithms, but you can't change from your best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:01:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0 0.5248539754440339 0.5356550580431177 0.5041911148365466\n",
      "[20:01:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.5289492494639028 0.5253252145031829 0.5075440067057837\n",
      "[20:01:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2 0.530723606168446 0.525020967291026 0.5075440067057837\n",
      "[20:01:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "3 0.5304368584387682 0.5219068613943235 0.5071248952221291\n",
      "[20:01:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "4 0.5273649445623968 0.5313119863984131 0.5058675607711651\n",
      "[20:01:46] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "5 0.5336481700118064 0.5139949109414759 0.5058675607711651\n",
      "[20:01:51] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "6 0.5303370786516854 0.5228040540540541 0.5062866722548198\n",
      "[20:01:55] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "7 0.5305348037471836 0.5229434806939004 0.5046102263202011\n",
      "[20:01:59] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "8 0.5283557246462965 0.5275305895439377 0.5062866722548198\n",
      "[20:02:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "9 0.5321220757629735 0.5167317345231456 0.5058675607711651\n",
      "[20:02:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "10 0.538066212501494 0.506043956043956 0.508382229673093\n",
      "[20:02:11] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "11 0.5295886456579264 0.5215272136474411 0.5041911148365466\n",
      "[20:02:15] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "12 0.5275262154432793 0.5313969571230982 0.5067057837384744\n",
      "[20:02:19] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "13 0.5239563567362429 0.5367832167832168 0.5067057837384744\n",
      "[20:02:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "14 0.5272945410917816 0.5299564270152506 0.508382229673093\n",
      "[20:02:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "15 0.5327594452415112 0.5185286851496019 0.508382229673093\n",
      "[20:02:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "16 0.530373001776199 0.5230207748455924 0.5067057837384744\n",
      "[20:02:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "17 0.5307195792493425 0.5218346608074704 0.5075440067057837\n",
      "[20:02:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "18 0.5328276842853756 0.5163911459792659 0.5058675607711651\n",
      "[20:02:43] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.5292572247432529 0.5249105422515827 0.5071248952221291\n",
      "[20:02:47] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "20 0.5308583024949266 0.5214876033057851 0.5058675607711651\n",
      "[20:02:51] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "21 0.5282660332541568 0.5280178422079732 0.5054484492875104\n",
      "[20:02:55] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "22 0.5317725752508361 0.5204951856946355 0.5067057837384744\n",
      "[20:02:59] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "23 0.5303774715398443 0.5215729109776078 0.5054484492875104\n",
      "[20:03:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "24 0.5272076372315035 0.5299145299145299 0.5062866722548198\n",
      "[20:03:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "25 0.5270367700072098 0.5310719131614654 0.5058675607711651\n",
      "[20:03:11] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "26 0.5340095465393795 0.5144747725392886 0.5054484492875104\n",
      "[20:03:15] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "27 0.5276483936462438 0.5280682443588333 0.5037720033528919\n",
      "[20:03:19] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "28 0.5321609250782944 0.5171390013495276 0.5062866722548198\n",
      "[20:03:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "29 0.5278704144830871 0.5283854887842703 0.5075440067057837\n",
      "trn    0.529897\n",
      "tst    0.523808\n",
      "oot    0.506329\n",
      "dtype: float64\n",
      "CPU times: user 5min 28s, sys: 2min 1s, total: 7min 29s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for niter in range(30):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "# here's where you put your final model of choice\n",
    "    model = xgb.XGBClassifier(n_estimators=20, max_depth=6)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['LGBM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    if(FDR3.loc[niter, 'oot'] > .56): break\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_eval = X_trn.copy()\n",
    "X_tst_eval = X_tst.copy()\n",
    "X_oot_eval = X_oot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883659</th>\n",
       "      <td>-3.270118</td>\n",
       "      <td>18.014020</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-3.043947</td>\n",
       "      <td>8.000937</td>\n",
       "      <td>1.634417</td>\n",
       "      <td>-8.223310</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887718</th>\n",
       "      <td>-3.239845</td>\n",
       "      <td>16.002093</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-3.015331</td>\n",
       "      <td>8.000937</td>\n",
       "      <td>5.048616</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862046</th>\n",
       "      <td>-3.229754</td>\n",
       "      <td>16.002093</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-3.005792</td>\n",
       "      <td>8.000937</td>\n",
       "      <td>6.755716</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943613</th>\n",
       "      <td>-3.229754</td>\n",
       "      <td>16.002093</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-3.005792</td>\n",
       "      <td>4.765118</td>\n",
       "      <td>1.634417</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920503</th>\n",
       "      <td>-3.239845</td>\n",
       "      <td>13.990166</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-3.015331</td>\n",
       "      <td>3.147209</td>\n",
       "      <td>1.634417</td>\n",
       "      <td>-7.989323</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875240</th>\n",
       "      <td>-3.260027</td>\n",
       "      <td>13.990166</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-3.034408</td>\n",
       "      <td>6.383028</td>\n",
       "      <td>6.755716</td>\n",
       "      <td>-7.989323</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931201</th>\n",
       "      <td>-3.239845</td>\n",
       "      <td>16.002093</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-3.015331</td>\n",
       "      <td>3.147209</td>\n",
       "      <td>1.634417</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849132</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>13.990166</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>4.765118</td>\n",
       "      <td>5.048616</td>\n",
       "      <td>-6.819389</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880299</th>\n",
       "      <td>-3.209572</td>\n",
       "      <td>16.002093</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-2.986715</td>\n",
       "      <td>8.000937</td>\n",
       "      <td>1.634417</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909416</th>\n",
       "      <td>-3.199481</td>\n",
       "      <td>16.002093</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-2.977176</td>\n",
       "      <td>4.765118</td>\n",
       "      <td>-0.072683</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894206</th>\n",
       "      <td>-2.422468</td>\n",
       "      <td>34.109434</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-2.242700</td>\n",
       "      <td>-0.088610</td>\n",
       "      <td>-0.072683</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.998199</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849348</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>16.002093</td>\n",
       "      <td>-0.094684</td>\n",
       "      <td>-0.052528</td>\n",
       "      <td>-0.082437</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>6.383028</td>\n",
       "      <td>6.755716</td>\n",
       "      <td>-6.039433</td>\n",
       "      <td>0.998164</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854763</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>21.300923</td>\n",
       "      <td>27.741998</td>\n",
       "      <td>23.302758</td>\n",
       "      <td>24.628024</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>24.180031</td>\n",
       "      <td>25.533814</td>\n",
       "      <td>-0.384753</td>\n",
       "      <td>0.998124</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998070</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>24.153671</td>\n",
       "      <td>22.183093</td>\n",
       "      <td>26.420784</td>\n",
       "      <td>27.921019</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>27.415850</td>\n",
       "      <td>28.948014</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.998124</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973803</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>14.169054</td>\n",
       "      <td>18.477156</td>\n",
       "      <td>15.507693</td>\n",
       "      <td>16.395538</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.090484</td>\n",
       "      <td>16.998315</td>\n",
       "      <td>-4.054091</td>\n",
       "      <td>0.998124</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931731</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>14.169054</td>\n",
       "      <td>18.477156</td>\n",
       "      <td>15.507693</td>\n",
       "      <td>16.395538</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.090484</td>\n",
       "      <td>16.998315</td>\n",
       "      <td>-5.755813</td>\n",
       "      <td>0.998124</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854785</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>18.448175</td>\n",
       "      <td>14.771219</td>\n",
       "      <td>20.184732</td>\n",
       "      <td>21.335030</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>20.944212</td>\n",
       "      <td>22.119615</td>\n",
       "      <td>-5.816589</td>\n",
       "      <td>0.998124</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969702</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>19.874549</td>\n",
       "      <td>11.065283</td>\n",
       "      <td>21.743745</td>\n",
       "      <td>22.981527</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>22.562122</td>\n",
       "      <td>20.412515</td>\n",
       "      <td>-7.911328</td>\n",
       "      <td>0.998124</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916736</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>31.285540</td>\n",
       "      <td>40.712777</td>\n",
       "      <td>34.215849</td>\n",
       "      <td>36.153506</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>35.505397</td>\n",
       "      <td>37.483513</td>\n",
       "      <td>-3.462188</td>\n",
       "      <td>0.998124</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916735</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>29.859166</td>\n",
       "      <td>38.859809</td>\n",
       "      <td>32.656836</td>\n",
       "      <td>34.507009</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>33.887487</td>\n",
       "      <td>35.776413</td>\n",
       "      <td>-3.628661</td>\n",
       "      <td>0.998124</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fulladdress_day_since  name_dob_count_30  \\\n",
       "883659              -3.270118          18.014020   \n",
       "887718              -3.239845          16.002093   \n",
       "862046              -3.229754          16.002093   \n",
       "943613              -3.229754          16.002093   \n",
       "920503              -3.239845          13.990166   \n",
       "875240              -3.260027          13.990166   \n",
       "931201              -3.239845          16.002093   \n",
       "849132              -3.280209          13.990166   \n",
       "880299              -3.209572          16.002093   \n",
       "909416              -3.199481          16.002093   \n",
       "894206              -2.422468          34.109434   \n",
       "849348              -3.280209          16.002093   \n",
       "854763              -3.280209          -0.093321   \n",
       "998070              -3.280209          -0.093321   \n",
       "973803              -3.280209          -0.093321   \n",
       "931731              -3.280209          -0.093321   \n",
       "854785              -3.280209          -0.093321   \n",
       "969702              -3.280209          -0.093321   \n",
       "916736              -3.280209          -0.093321   \n",
       "916735              -3.280209          -0.093321   \n",
       "\n",
       "        address_unique_count_for_name_homephone_60  \\\n",
       "883659                                   -0.094684   \n",
       "887718                                   -0.094684   \n",
       "862046                                   -0.094684   \n",
       "943613                                   -0.094684   \n",
       "920503                                   -0.094684   \n",
       "875240                                   -0.094684   \n",
       "931201                                   -0.094684   \n",
       "849132                                   -0.094684   \n",
       "880299                                   -0.094684   \n",
       "909416                                   -0.094684   \n",
       "894206                                   -0.094684   \n",
       "849348                                   -0.094684   \n",
       "854763                                   21.300923   \n",
       "998070                                   24.153671   \n",
       "973803                                   14.169054   \n",
       "931731                                   14.169054   \n",
       "854785                                   18.448175   \n",
       "969702                                   19.874549   \n",
       "916736                                   31.285540   \n",
       "916735                                   29.859166   \n",
       "\n",
       "        fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "883659                                     -0.052528   \n",
       "887718                                     -0.052528   \n",
       "862046                                     -0.052528   \n",
       "943613                                     -0.052528   \n",
       "920503                                     -0.052528   \n",
       "875240                                     -0.052528   \n",
       "931201                                     -0.052528   \n",
       "849132                                     -0.052528   \n",
       "880299                                     -0.052528   \n",
       "909416                                     -0.052528   \n",
       "894206                                     -0.052528   \n",
       "849348                                     -0.052528   \n",
       "854763                                     27.741998   \n",
       "998070                                     22.183093   \n",
       "973803                                     18.477156   \n",
       "931731                                     18.477156   \n",
       "854785                                     14.771219   \n",
       "969702                                     11.065283   \n",
       "916736                                     40.712777   \n",
       "916735                                     38.859809   \n",
       "\n",
       "        address_unique_count_for_homephone_name_dob_30  \\\n",
       "883659                                       -0.082437   \n",
       "887718                                       -0.082437   \n",
       "862046                                       -0.082437   \n",
       "943613                                       -0.082437   \n",
       "920503                                       -0.082437   \n",
       "875240                                       -0.082437   \n",
       "931201                                       -0.082437   \n",
       "849132                                       -0.082437   \n",
       "880299                                       -0.082437   \n",
       "909416                                       -0.082437   \n",
       "894206                                       -0.082437   \n",
       "849348                                       -0.082437   \n",
       "854763                                       23.302758   \n",
       "998070                                       26.420784   \n",
       "973803                                       15.507693   \n",
       "931731                                       15.507693   \n",
       "854785                                       20.184732   \n",
       "969702                                       21.743745   \n",
       "916736                                       34.215849   \n",
       "916735                                       32.656836   \n",
       "\n",
       "        address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "883659                                 -0.069436          -3.043947   \n",
       "887718                                 -0.069436          -3.015331   \n",
       "862046                                 -0.069436          -3.005792   \n",
       "943613                                 -0.069436          -3.005792   \n",
       "920503                                 -0.069436          -3.015331   \n",
       "875240                                 -0.069436          -3.034408   \n",
       "931201                                 -0.069436          -3.015331   \n",
       "849132                                 -0.069436          -3.053486   \n",
       "880299                                 -0.069436          -2.986715   \n",
       "909416                                 -0.069436          -2.977176   \n",
       "894206                                 -0.069436          -2.242700   \n",
       "849348                                 -0.069436          -3.053486   \n",
       "854763                                 24.628024          -3.053486   \n",
       "998070                                 27.921019          -3.053486   \n",
       "973803                                 16.395538          -3.053486   \n",
       "931731                                 16.395538          -3.053486   \n",
       "854785                                 21.335030          -3.053486   \n",
       "969702                                 22.981527          -3.053486   \n",
       "916736                                 36.153506          -3.053486   \n",
       "916735                                 34.507009          -3.053486   \n",
       "\n",
       "        address_count_14  address_count_7  address_count_0_by_30  predicted  \\\n",
       "883659          8.000937         1.634417              -8.223310   0.998521   \n",
       "887718          8.000937         5.048616              -8.119316   0.998521   \n",
       "862046          8.000937         6.755716              -8.119316   0.998521   \n",
       "943613          4.765118         1.634417              -8.119316   0.998521   \n",
       "920503          3.147209         1.634417              -7.989323   0.998521   \n",
       "875240          6.383028         6.755716              -7.989323   0.998521   \n",
       "931201          3.147209         1.634417              -8.119316   0.998521   \n",
       "849132          4.765118         5.048616              -6.819389   0.998521   \n",
       "880299          8.000937         1.634417              -8.119316   0.998421   \n",
       "909416          4.765118        -0.072683              -8.119316   0.998421   \n",
       "894206         -0.088610        -0.072683               0.200213   0.998199   \n",
       "849348          6.383028         6.755716              -6.039433   0.998164   \n",
       "854763         24.180031        25.533814              -0.384753   0.998124   \n",
       "998070         27.415850        28.948014              -8.119316   0.998124   \n",
       "973803         16.090484        16.998315              -4.054091   0.998124   \n",
       "931731         16.090484        16.998315              -5.755813   0.998124   \n",
       "854785         20.944212        22.119615              -5.816589   0.998124   \n",
       "969702         22.562122        20.412515              -7.911328   0.998124   \n",
       "916736         35.505397        37.483513              -3.462188   0.998124   \n",
       "916735         33.887487        35.776413              -3.628661   0.998124   \n",
       "\n",
       "        Fraud  \n",
       "883659    1.0  \n",
       "887718    1.0  \n",
       "862046    0.0  \n",
       "943613    1.0  \n",
       "920503    1.0  \n",
       "875240    1.0  \n",
       "931201    1.0  \n",
       "849132    1.0  \n",
       "880299    1.0  \n",
       "909416    1.0  \n",
       "894206    1.0  \n",
       "849348    1.0  \n",
       "854763    1.0  \n",
       "998070    1.0  \n",
       "973803    1.0  \n",
       "931731    1.0  \n",
       "854785    1.0  \n",
       "969702    1.0  \n",
       "916736    1.0  \n",
       "916735    1.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['bin','#recs','#g','#b','%g','%b','tot','cg','cb','%cg','FDR','KS','FPR']\n",
    "FDR_trn = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_tst = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_oot = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "trn_sorted = X_trn_eval.sort_values('predicted',ascending=False)\n",
    "tst_sorted = X_tst_eval.sort_values('predicted',ascending=False)\n",
    "oot_sorted = X_oot_eval.sort_values('predicted',ascending=False)\n",
    "bad_tot_trn = sum(X_trn_eval.loc[:, 'Fraud'])\n",
    "bad_tot_tst = sum(X_tst_eval.loc[:, 'Fraud'])\n",
    "bad_tot_oot = sum(X_oot_eval.loc[:, 'Fraud'])\n",
    "num_tot_trn = len(X_trn_eval)\n",
    "num_tot_tst = len(X_tst_eval)\n",
    "num_tot_oot = len(X_oot_eval)\n",
    "good_tot_trn = num_tot_trn - bad_tot_trn\n",
    "good_tot_tst = num_tot_tst - bad_tot_tst\n",
    "good_tot_oot = num_tot_oot - bad_tot_oot\n",
    "oot_sorted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>#recs</th>\n",
       "      <th>#g</th>\n",
       "      <th>#b</th>\n",
       "      <th>%g</th>\n",
       "      <th>%b</th>\n",
       "      <th>tot</th>\n",
       "      <th>cg</th>\n",
       "      <th>cb</th>\n",
       "      <th>%cg</th>\n",
       "      <th>FDR</th>\n",
       "      <th>KS</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>30.510511</td>\n",
       "      <td>69.489489</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>0.309554</td>\n",
       "      <td>48.491199</td>\n",
       "      <td>48.181645</td>\n",
       "      <td>0.439067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>98.438438</td>\n",
       "      <td>1.561562</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>2147.0</td>\n",
       "      <td>1183.0</td>\n",
       "      <td>1.308293</td>\n",
       "      <td>49.580889</td>\n",
       "      <td>48.272596</td>\n",
       "      <td>1.814877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1637.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>98.318318</td>\n",
       "      <td>1.681682</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>3784.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>2.305813</td>\n",
       "      <td>50.754401</td>\n",
       "      <td>48.448588</td>\n",
       "      <td>3.124690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>98.858859</td>\n",
       "      <td>1.141141</td>\n",
       "      <td>6660.0</td>\n",
       "      <td>5430.0</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>3.308817</td>\n",
       "      <td>51.550712</td>\n",
       "      <td>48.241896</td>\n",
       "      <td>4.414634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>99.339339</td>\n",
       "      <td>0.660661</td>\n",
       "      <td>159833.0</td>\n",
       "      <td>157494.0</td>\n",
       "      <td>2339.0</td>\n",
       "      <td>95.970312</td>\n",
       "      <td>98.030176</td>\n",
       "      <td>2.059864</td>\n",
       "      <td>67.333903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1657.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>99.519520</td>\n",
       "      <td>0.480480</td>\n",
       "      <td>161498.0</td>\n",
       "      <td>159151.0</td>\n",
       "      <td>2347.0</td>\n",
       "      <td>96.980019</td>\n",
       "      <td>98.365465</td>\n",
       "      <td>1.385446</td>\n",
       "      <td>67.810396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>99.159159</td>\n",
       "      <td>0.840841</td>\n",
       "      <td>163163.0</td>\n",
       "      <td>160802.0</td>\n",
       "      <td>2361.0</td>\n",
       "      <td>97.986070</td>\n",
       "      <td>98.952221</td>\n",
       "      <td>0.966151</td>\n",
       "      <td>68.107582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>99.099099</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>164828.0</td>\n",
       "      <td>162452.0</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>98.991512</td>\n",
       "      <td>99.580889</td>\n",
       "      <td>0.589377</td>\n",
       "      <td>68.372054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1655.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>99.399399</td>\n",
       "      <td>0.600601</td>\n",
       "      <td>166493.0</td>\n",
       "      <td>164107.0</td>\n",
       "      <td>2386.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.779128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin   #recs      #g      #b         %g         %b       tot        cg  \\\n",
       "0      0.0     0.0     0.0     0.0   0.000000   0.000000       0.0       0.0   \n",
       "1      1.0  1665.0   508.0  1157.0  30.510511  69.489489    1665.0     508.0   \n",
       "2      2.0  1665.0  1639.0    26.0  98.438438   1.561562    3330.0    2147.0   \n",
       "3      3.0  1665.0  1637.0    28.0  98.318318   1.681682    4995.0    3784.0   \n",
       "4      4.0  1665.0  1646.0    19.0  98.858859   1.141141    6660.0    5430.0   \n",
       "..     ...     ...     ...     ...        ...        ...       ...       ...   \n",
       "96    96.0  1665.0  1654.0    11.0  99.339339   0.660661  159833.0  157494.0   \n",
       "97    97.0  1665.0  1657.0     8.0  99.519520   0.480480  161498.0  159151.0   \n",
       "98    98.0  1665.0  1651.0    14.0  99.159159   0.840841  163163.0  160802.0   \n",
       "99    99.0  1665.0  1650.0    15.0  99.099099   0.900901  164828.0  162452.0   \n",
       "100  100.0  1665.0  1655.0    10.0  99.399399   0.600601  166493.0  164107.0   \n",
       "\n",
       "         cb         %cg         FDR         KS        FPR  \n",
       "0       0.0    0.000000    0.000000   0.000000   0.000000  \n",
       "1    1157.0    0.309554   48.491199  48.181645   0.439067  \n",
       "2    1183.0    1.308293   49.580889  48.272596   1.814877  \n",
       "3    1211.0    2.305813   50.754401  48.448588   3.124690  \n",
       "4    1230.0    3.308817   51.550712  48.241896   4.414634  \n",
       "..      ...         ...         ...        ...        ...  \n",
       "96   2339.0   95.970312   98.030176   2.059864  67.333903  \n",
       "97   2347.0   96.980019   98.365465   1.385446  67.810396  \n",
       "98   2361.0   97.986070   98.952221   0.966151  68.107582  \n",
       "99   2376.0   98.991512   99.580889   0.589377  68.372054  \n",
       "100  2386.0  100.000000  100.000000   0.000000  68.779128  \n",
       "\n",
       "[101 rows x 13 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(101):\n",
    "    percent_rows_trn = int(round(X_trn_eval.shape[0]*0.01*i))\n",
    "    percent_rows_tst = int(round(X_tst_eval.shape[0]*0.01*i))\n",
    "    percent_rows_oot = int(round(X_oot_eval.shape[0]*0.01*i))\n",
    "    temp_trn = trn_sorted.head(percent_rows_trn)\n",
    "    temp_tst = tst_sorted.head(percent_rows_tst)\n",
    "    temp_oot = oot_sorted.head(percent_rows_oot)\n",
    "    num_bad_trn = sum(temp_trn.loc[:,'Fraud'])\n",
    "    num_bad_tst = sum(temp_tst.loc[:,'Fraud'])\n",
    "    num_bad_oot = sum(temp_oot.loc[:,'Fraud'])\n",
    "    num_tot_trn = len(temp_trn)\n",
    "    num_tot_tst = len(temp_tst)\n",
    "    num_tot_oot = len(temp_oot)\n",
    "    num_good_trn = num_tot_trn - num_bad_trn\n",
    "    num_good_tst = num_tot_tst - num_bad_tst\n",
    "    num_good_oot = num_tot_oot - num_bad_oot\n",
    "    \n",
    "    FDR_trn.loc[i, 'bin'] = i\n",
    "    FDR_trn.loc[i,'#recs'] = 0\n",
    "    FDR_trn.loc[i, 'tot'] = num_tot_trn\n",
    "    FDR_trn.loc[i, 'cg'] = num_good_trn\n",
    "    FDR_trn.loc[i, 'cb'] = num_bad_trn\n",
    "    FDR_tst.loc[i, 'bin'] = i\n",
    "    FDR_tst.loc[i, 'tot'] = num_tot_tst\n",
    "    FDR_tst.loc[i, 'cg'] = num_good_tst\n",
    "    FDR_tst.loc[i, 'cb'] = num_bad_tst\n",
    "    FDR_oot.loc[i, 'bin'] = i\n",
    "    FDR_oot.loc[i, 'tot'] = num_tot_oot\n",
    "    FDR_oot.loc[i, 'cg'] = num_good_oot\n",
    "    FDR_oot.loc[i, 'cb'] = num_bad_oot\n",
    "    if i != 0:\n",
    "        FDR_trn.loc[i, '#g'] = num_good_trn - FDR_trn.loc[i-1, 'cg']\n",
    "        FDR_trn.loc[i, '#b'] = num_bad_trn - FDR_trn.loc[i-1, 'cb']\n",
    "        FDR_trn.loc[i,'#recs'] = FDR_trn.loc[i, '#g'] + FDR_trn.loc[i, '#b']\n",
    "        FDR_trn.loc[i, '%g'] = 100* (num_good_trn - FDR_trn.loc[i-1, 'cg']) / (num_tot_trn - FDR_trn.loc[i-1, 'tot'])\n",
    "        FDR_trn.loc[i, '%b'] = 100 - FDR_trn.loc[i, '%g']\n",
    "        FDR_trn.loc[i, '%cg'] = 100 * num_good_trn / good_tot_trn\n",
    "        FDR_trn.loc[i, 'FDR'] = 100 * num_bad_trn / bad_tot_trn\n",
    "        FDR_trn.loc[i, 'KS'] = FDR_trn.loc[i, 'FDR'] - FDR_trn.loc[i, '%cg']\n",
    "        FDR_trn.loc[i, 'FPR'] = num_good_trn / num_bad_trn\n",
    "        FDR_tst.loc[i, '#g'] = num_good_tst - FDR_tst.loc[i-1, 'cg']\n",
    "        FDR_tst.loc[i, '#b'] = num_bad_tst - FDR_tst.loc[i-1, 'cb']\n",
    "        FDR_tst.loc[i,'#recs'] = FDR_tst.loc[i, '#g'] + FDR_tst.loc[i, '#b']\n",
    "        FDR_tst.loc[i, '%g'] = 100* (num_good_tst - FDR_tst.loc[i-1, 'cg']) / (num_tot_tst - FDR_tst.loc[i-1, 'tot'])\n",
    "        FDR_tst.loc[i, '%b'] = 100 - FDR_tst.loc[i, '%g']\n",
    "        FDR_tst.loc[i, '%cg'] = 100 * num_good_tst / good_tot_tst\n",
    "        FDR_tst.loc[i, 'FDR'] = 100 * num_bad_tst / bad_tot_tst\n",
    "        FDR_tst.loc[i, 'KS'] = FDR_tst.loc[i, 'FDR'] - FDR_tst.loc[i, '%cg']\n",
    "        FDR_tst.loc[i, 'FPR'] = num_good_tst / num_bad_tst\n",
    "        FDR_oot.loc[i, '#g'] = num_good_oot - FDR_oot.loc[i-1, 'cg']\n",
    "        FDR_oot.loc[i, '#b'] = num_bad_oot - FDR_oot.loc[i-1, 'cb']\n",
    "        FDR_oot.loc[i,'#recs'] = FDR_oot.loc[i, '#g'] + FDR_oot.loc[i, '#b']\n",
    "        FDR_oot.loc[i, '%g'] = 100* (num_good_oot - FDR_oot.loc[i-1, 'cg']) / (num_tot_oot - FDR_oot.loc[i-1, 'tot'])\n",
    "        FDR_oot.loc[i, '%b'] = 100 - FDR_oot.loc[i, '%g']\n",
    "        FDR_oot.loc[i, '%cg'] = 100 * num_good_oot / good_tot_oot\n",
    "        FDR_oot.loc[i, 'FDR'] = 100 * num_bad_oot / bad_tot_oot\n",
    "        FDR_oot.loc[i, 'KS'] = FDR_oot.loc[i, 'FDR'] - FDR_oot.loc[i, '%cg']\n",
    "        FDR_oot.loc[i, 'FPR'] = num_good_oot / num_bad_oot\n",
    "\n",
    "FDR_oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR3.to_csv('FDR3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_trn.to_csv('FDR_trn.csv', index=False)\n",
    "FDR_tst.to_csv('FDR_tst.csv', index=False)\n",
    "FDR_oot.to_csv('FDR_oot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:06:44.263460\n"
     ]
    }
   ],
   "source": [
    "print(\"duration: \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
